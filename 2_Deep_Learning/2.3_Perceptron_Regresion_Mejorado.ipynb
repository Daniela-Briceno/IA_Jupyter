{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516589d5",
   "metadata": {},
   "source": [
    "# Predicción de Contaminación MP10 con Perceptrón Mejorado\n",
    "\n",
    "Este notebook implementa un perceptrón simple para regresión con técnicas avanzadas como:\n",
    "- Batch Normalization\n",
    "- Gradient Clipping\n",
    "- Weight Decay\n",
    "- Warm Restarts (cosine annealing LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f04a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a8407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv(\"AllData1.csv\")\n",
    "X = df.drop(columns=[\"mp10_val\"]).values\n",
    "y = df[\"mp10_val\"].values.reshape(-1, 1)\n",
    "\n",
    "# Escalado\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# División\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790c816-6c3c-4bcc-85e0-feabceea2de3",
   "metadata": {},
   "source": [
    "## Perceptron simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c518b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Perceptrón con mejoras\n",
    "class PerceptronRegresionAvanzado:\n",
    "  def __init__(self, input_size, lr=0.01, lambda_wd=1e-4, clip_value=1.0, eta_min=0.001, eta_max=0.1, T=50):\n",
    "    self.W = np.random.randn(input_size, 1) * np.sqrt(2. / input_size)\n",
    "    self.b = np.zeros((1,))\n",
    "    self.lr = lr\n",
    "    self.lambda_wd = lambda_wd\n",
    "    self.clip_value = clip_value\n",
    "    self.eta_min = eta_min\n",
    "    self.eta_max = eta_max\n",
    "    self.T = T\n",
    "    self.gamma = np.ones((1,))\n",
    "    self.beta = np.zeros((1,))\n",
    "\n",
    "  def batch_norm(self, z):\n",
    "    mu = np.mean(z, axis=0)\n",
    "    sigma = np.std(z, axis=0)\n",
    "    z_norm = (z - mu) / (sigma + 1e-8)\n",
    "    return self.gamma * z_norm + self.beta\n",
    "\n",
    "  def forward(self, X):\n",
    "    z = np.dot(X, self.W) + self.b\n",
    "    z_bn = self.batch_norm(z)\n",
    "    return z_bn\n",
    "\n",
    "  def backward(self, X, y_true, y_pred, t):\n",
    "    m = X.shape[0]\n",
    "    grad = (y_pred - y_true) / m\n",
    "\n",
    "    dW = np.dot(X.T, grad)\n",
    "    db = np.sum(grad)\n",
    "\n",
    "    # Weight decay\n",
    "    dW += self.lambda_wd * self.W\n",
    "\n",
    "    # Clipping\n",
    "    dW = np.clip(dW, -self.clip_value, self.clip_value)\n",
    "    db = np.clip(db, -self.clip_value, self.clip_value)\n",
    "\n",
    "    # Cosine annealing LR\n",
    "    lr_t = self.eta_min + 0.5 * (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * t / self.T))\n",
    "\n",
    "    # Actualizar\n",
    "    self.W -= lr_t * dW\n",
    "    self.b -= lr_t * db\n",
    "\n",
    "  def train(self, X, y, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "      y_pred = self.forward(X)\n",
    "      loss = np.mean((y_pred - y) ** 2)\n",
    "      self.backward(X, y, y_pred, epoch % self.T)\n",
    "      if epoch % 10 == 0:\n",
    "        print(f\"Época {epoch}: MSE={loss:.4f}\")\n",
    "\n",
    "  def predict(self, X):\n",
    "    return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea58728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0: MSE=2.4471\n",
      "Época 10: MSE=1.5986\n",
      "Época 20: MSE=1.3326\n",
      "Época 30: MSE=1.2981\n",
      "Época 40: MSE=1.3027\n",
      "Época 50: MSE=1.3055\n",
      "Época 60: MSE=1.6429\n",
      "Época 70: MSE=1.5526\n",
      "Época 80: MSE=1.5035\n",
      "Época 90: MSE=1.3802\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "modelo = PerceptronRegresionAvanzado(input_size=X.shape[1])\n",
    "modelo.train(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36d792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (escalado): 1.7072\n",
      "MSE real (μg/m³): 114.4546\n"
     ]
    }
   ],
   "source": [
    "# Evaluación final\n",
    "y_pred_test = modelo.predict(X_test)\n",
    "mse_test = np.mean((y_pred_test - y_test) ** 2)\n",
    "mse_real = np.mean((scaler_y.inverse_transform(y_pred_test) - scaler_y.inverse_transform(y_test)) ** 2)\n",
    "print(f\"MSE (escalado): {mse_test:.4f}\")\n",
    "print(f\"MSE real (μg/m³): {mse_real:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa7b98-8e05-4a07-9607-c0eae0b0f344",
   "metadata": {},
   "source": [
    "## Perceptron Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f830ef40-0564-4bde-b0f5-9877c881ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP con 2 capas ocultas y mejoras avanzadas\n",
    "def relu(x): return np.maximum(0, x)\n",
    "def relu_derivada(x): return (x > 0).astype(float)\n",
    "\n",
    "class MLP_Regresion_Mejorado:\n",
    "  def __init__(self, capas, lr=0.01, lambda_wd=1e-4, clip_value=1.0, eta_min=0.001, eta_max=0.1, T=50):\n",
    "    self.capas = capas\n",
    "    self.lr = lr\n",
    "    self.lambda_wd = lambda_wd\n",
    "    self.clip_value = clip_value\n",
    "    self.eta_min = eta_min\n",
    "    self.eta_max = eta_max\n",
    "    self.T = T\n",
    "\n",
    "    self.W = []\n",
    "    self.b = []\n",
    "    self.gamma = []\n",
    "    self.beta = []\n",
    "\n",
    "    for i in range(len(capas) - 1):\n",
    "      self.W.append(np.random.randn(capas[i], capas[i+1]) * np.sqrt(2. / capas[i]))\n",
    "      self.b.append(np.zeros((1, capas[i+1])))\n",
    "      self.gamma.append(np.ones((1, capas[i+1])))\n",
    "      self.beta.append(np.zeros((1, capas[i+1])))\n",
    "\n",
    "  def batch_norm(self, z, gamma, beta):\n",
    "    mu = np.mean(z, axis=0)\n",
    "    sigma = np.std(z, axis=0)\n",
    "    z_norm = (z - mu) / (sigma + 1e-8)\n",
    "    return gamma * z_norm + beta\n",
    "\n",
    "  def forward(self, X):\n",
    "    self.a = [X]\n",
    "    self.z = []\n",
    "    for i in range(len(self.W) - 1):\n",
    "      z_i = np.dot(self.a[-1], self.W[i]) + self.b[i]\n",
    "      z_bn = self.batch_norm(z_i, self.gamma[i], self.beta[i])\n",
    "      a_i = relu(z_bn)\n",
    "      self.z.append(z_bn)\n",
    "      self.a.append(a_i)\n",
    "    z_final = np.dot(self.a[-1], self.W[-1]) + self.b[-1]\n",
    "    self.z.append(z_final)\n",
    "    self.a.append(z_final)\n",
    "    return z_final\n",
    "\n",
    "  def backward(self, y_true, t):\n",
    "    m = y_true.shape[0]\n",
    "    grad = (self.a[-1] - y_true) / m\n",
    "\n",
    "    for i in reversed(range(len(self.W))):\n",
    "      dW = np.dot(self.a[i].T, grad)\n",
    "      db = np.sum(grad, axis=0, keepdims=True)\n",
    "\n",
    "      dW += self.lambda_wd * self.W[i]\n",
    "      dW = np.clip(dW, -self.clip_value, self.clip_value)\n",
    "      db = np.clip(db, -self.clip_value, self.clip_value)\n",
    "\n",
    "      lr_t = self.eta_min + 0.5 * (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * t / self.T))\n",
    "      self.W[i] -= lr_t * dW\n",
    "      self.b[i] -= lr_t * db\n",
    "\n",
    "      if i != 0:\n",
    "        grad = np.dot(grad, self.W[i].T) * relu_derivada(self.z[i-1])\n",
    "\n",
    "  def train(self, X, y, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "      y_pred = self.forward(X)\n",
    "      loss = np.mean((y_pred - y) ** 2)\n",
    "      self.backward(y, epoch % self.T)\n",
    "      if epoch % 10 == 0:\n",
    "        print(f\"Época {epoch}: MSE={loss:.4f}\")\n",
    "\n",
    "  def predict(self, X):\n",
    "    return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7eae23-c1ca-4885-bac8-d010e4824122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0: MSE=1.8933\n",
      "Época 10: MSE=0.8015\n",
      "Época 20: MSE=0.6687\n",
      "Época 30: MSE=0.6198\n",
      "Época 40: MSE=0.6022\n",
      "Época 50: MSE=0.5988\n",
      "Época 60: MSE=0.5379\n",
      "Época 70: MSE=0.4979\n",
      "Época 80: MSE=0.4750\n",
      "Época 90: MSE=0.4656\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "mlp = MLP_Regresion_Mejorado(capas=[X.shape[1], 32, 16, 1])\n",
    "mlp.train(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd11d14c-8486-47a0-be00-142193702666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MSE (escalado): 1.0516\n",
      " MSE real (μg/m³): 70.5021\n"
     ]
    }
   ],
   "source": [
    "# Evaluación\n",
    "y_pred_test = mlp.predict(X_test)\n",
    "mse_test = np.mean((y_pred_test - y_test) ** 2)\n",
    "mse_real = np.mean((scaler_y.inverse_transform(y_pred_test) - scaler_y.inverse_transform(y_test)) ** 2)\n",
    "print(f\" MSE (escalado): {mse_test:.4f}\")\n",
    "print(f\" MSE real (μg/m³): {mse_real:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55626d-08e4-41fb-af37-c0b0fc5e9cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
